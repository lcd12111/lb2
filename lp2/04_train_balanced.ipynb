{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Unbalanced Data\n",
      "F1-score (avg): 0.6729166666666667  std: 0.0771396190898901\n",
      "Accuracy (avg): 0.875  std: 0.04097217358481802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 SMOTE Balanced\n",
      "F1-score (avg): 0.9366853278505783  std: 0.02994473666123673\n",
      "Accuracy (avg): 0.9324949698189134  std: 0.035703515251863244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 ADASYN Balanced\n",
      "F1-score (avg): 0.9435470085470086  std: 0.029256280415501497\n",
      "Accuracy (avg): 0.9428571428571428  std: 0.030304576336566306\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# --------------------------------\n",
    "# 📂 2. 加载归一化数据\n",
    "# --------------------------------\n",
    "df = pd.read_csv(\"../data/train_robot_sorted_v1.csv\")  # 或 train_robot_sorted_v1.csv,train_robot_v1.csv\n",
    "X = df.drop(columns=[\"Target\"])\n",
    "y = df[\"Target\"]\n",
    "\n",
    "# 可选：MinMaxScaler 再次确认归一化\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# --------------------------------\n",
    "# 🧠 3. 定义模型结构（使用最佳结构）\n",
    "# --------------------------------\n",
    "def get_model():\n",
    "    return MLPClassifier(\n",
    "        hidden_layer_sizes=(128, 64),\n",
    "        activation='relu',\n",
    "        solver='lbfgs',\n",
    "        max_iter=500,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "# --------------------------------\n",
    "# ⚖️ 4. 定义评估函数\n",
    "# --------------------------------\n",
    "def evaluate(X, y, title):\n",
    "    model = get_model()\n",
    "    scores = cross_validate(model, X, y, cv=4, scoring={\"f1\": \"f1\", \"accuracy\": \"accuracy\"})\n",
    "    print(f\"\\n📊 {title}\")\n",
    "    print(\"F1-score (avg):\", scores['test_f1'].mean(), \" std:\", scores['test_f1'].std())\n",
    "    print(\"Accuracy (avg):\", scores['test_accuracy'].mean(), \" std:\", scores['test_accuracy'].std())\n",
    "    return scores\n",
    "\n",
    "# --------------------------------\n",
    "# ✅ 5. 原始不平衡数据评估\n",
    "# --------------------------------\n",
    "raw_scores = evaluate(X, y, \"Unbalanced Data\")\n",
    "\n",
    "# --------------------------------\n",
    "# ⚙️ 6. SMOTE 平衡\n",
    "# --------------------------------\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "smote_scores = evaluate(X_smote, y_smote, \"SMOTE Balanced\")\n",
    "\n",
    "# --------------------------------\n",
    "# ⚙️ 7. ADASYN 平衡\n",
    "# --------------------------------\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_ada, y_ada = adasyn.fit_resample(X, y)\n",
    "adasyn_scores = evaluate(X_ada, y_ada, \"ADASYN Balanced\")\n",
    "\n",
    "# --------------------------------\n",
    "# 📈 8. 可视化对比\n",
    "# --------------------------------\n",
    "labels = ['Raw', 'SMOTE', 'ADASYN']\n",
    "f1_avgs = [raw_scores['test_f1'].mean(), smote_scores['test_f1'].mean(), adasyn_scores['test_f1'].mean()]\n",
    "acc_avgs = [raw_scores['test_accuracy'].mean(), smote_scores['test_accuracy'].mean(), adasyn_scores['test_accuracy'].mean()]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(labels, f1_avgs, alpha=0.7, label=\"F1-score\")\n",
    "plt.bar(labels, acc_avgs, alpha=0.7, label=\"Accuracy\", bottom=f1_avgs)\n",
    "plt.title(\"Comparison: Raw vs SMOTE vs ADASYN\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "layers",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "activation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "solver",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "F1-avg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1-std",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Acc-avg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Acc-std",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "42ddb937-0310-4580-9bce-feb42d000916",
       "rows": [
        [
         "0",
         "(64,)",
         "relu",
         "lbfgs",
         "0.9486111111111112",
         "0.024335299261021157",
         "0.9469818913480885",
         "0.02494868401910991"
        ],
        [
         "1",
         "(128, 64)",
         "relu",
         "lbfgs",
         "0.9480158730158731",
         "0.02512566050520116",
         "0.9469818913480885",
         "0.02494868401910991"
        ],
        [
         "2",
         "(128, 64, 32)",
         "relu",
         "lbfgs",
         "0.947533191573071",
         "0.012609587220509363",
         "0.9468812877263582",
         "0.011405984140684191"
        ],
        [
         "3",
         "(64, 32)",
         "tanh",
         "lbfgs",
         "0.942316586986033",
         "0.025546199346932776",
         "0.9398390342052314",
         "0.027062561240406232"
        ],
        [
         "4",
         "(100, 50, 25, 10)",
         "relu",
         "lbfgs",
         "0.9413138825324181",
         "0.01978299666287395",
         "0.9398390342052314",
         "0.02064605947659613"
        ],
        [
         "5",
         "(50, 25, 12)",
         "relu",
         "lbfgs",
         "0.9234200072228242",
         "0.015080088811423047",
         "0.9185110663983904",
         "0.01801057725348908"
        ],
        [
         "6",
         "(50, 25, 12)",
         "tanh",
         "lbfgs",
         "0.9086016114491313",
         "0.054756139287804574",
         "0.9042756539235413",
         "0.05909062722145522"
        ],
        [
         "7",
         "(50, 25, 12)",
         "tanh",
         "lbfgs",
         "0.9086016114491313",
         "0.054756139287804574",
         "0.9042756539235413",
         "0.05909062722145522"
        ],
        [
         "8",
         "(50, 25, 12, 6)",
         "relu",
         "adam",
         "0.9082770356315105",
         "0.03195144505948535",
         "0.9008048289738431",
         "0.038689123703919436"
        ],
        [
         "9",
         "(50, 50, 25)",
         "relu",
         "adam",
         "0.8900358692025359",
         "0.04392588461577695",
         "0.8757545271629779",
         "0.05651622794587403"
        ],
        [
         "10",
         "(64, 32, 16, 8)",
         "relu",
         "lbfgs",
         "0.8757098307845775",
         "0.08892854144644433",
         "0.8472334004024145",
         "0.1264706671202256"
        ],
        [
         "11",
         "(50, 25, 12)",
         "relu",
         "adam",
         "0.8738595162349139",
         "0.03410877696284288",
         "0.8653420523138833",
         "0.04503119138188732"
        ],
        [
         "12",
         "(50, 25, 12)",
         "relu",
         "adam",
         "0.8738595162349139",
         "0.03410877696284288",
         "0.8653420523138833",
         "0.04503119138188732"
        ],
        [
         "13",
         "(50, 25, 12, 6)",
         "relu",
         "lbfgs",
         "0.8524080086580087",
         "0.027334540404869465",
         "0.847635814889336",
         "0.01739911934527578"
        ],
        [
         "14",
         "(50, 25, 12)",
         "tanh",
         "adam",
         "0.6216074580759048",
         "0.2597939178333755",
         "0.6490442655935613",
         "0.13914076456189742"
        ],
        [
         "15",
         "(50, 50, 25)",
         "tanh",
         "adam",
         "0.6077053693433003",
         "0.19265530166728068",
         "0.6062877263581489",
         "0.1461131325526284"
        ],
        [
         "16",
         "(100, 50)",
         "tanh",
         "adam",
         "0.5961853957772887",
         "0.23357072533790393",
         "0.5992957746478873",
         "0.12442951853808822"
        ],
        [
         "17",
         "(64, 32)",
         "tanh",
         "adam",
         "0.5679684006105504",
         "0.14247177296255562",
         "0.5218309859154929",
         "0.1389779591959609"
        ],
        [
         "18",
         "(64, 32)",
         "tanh",
         "sgd",
         "0.3693522543460406",
         "0.14866007953939475",
         "0.45060362173038226",
         "0.05782153228061243"
        ],
        [
         "19",
         "(50, 25, 12)",
         "logistic",
         "adam",
         "0.1650943396226415",
         "0.2859517842684467",
         "0.4964788732394366",
         "0.0035211267605633756"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layers</th>\n",
       "      <th>activation</th>\n",
       "      <th>solver</th>\n",
       "      <th>F1-avg</th>\n",
       "      <th>F1-std</th>\n",
       "      <th>Acc-avg</th>\n",
       "      <th>Acc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(64,)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.948611</td>\n",
       "      <td>0.024335</td>\n",
       "      <td>0.946982</td>\n",
       "      <td>0.024949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(128, 64)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.948016</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.946982</td>\n",
       "      <td>0.024949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(128, 64, 32)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.947533</td>\n",
       "      <td>0.012610</td>\n",
       "      <td>0.946881</td>\n",
       "      <td>0.011406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(64, 32)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.942317</td>\n",
       "      <td>0.025546</td>\n",
       "      <td>0.939839</td>\n",
       "      <td>0.027063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(100, 50, 25, 10)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.941314</td>\n",
       "      <td>0.019783</td>\n",
       "      <td>0.939839</td>\n",
       "      <td>0.020646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.923420</td>\n",
       "      <td>0.015080</td>\n",
       "      <td>0.918511</td>\n",
       "      <td>0.018011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.908602</td>\n",
       "      <td>0.054756</td>\n",
       "      <td>0.904276</td>\n",
       "      <td>0.059091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.908602</td>\n",
       "      <td>0.054756</td>\n",
       "      <td>0.904276</td>\n",
       "      <td>0.059091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(50, 25, 12, 6)</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.908277</td>\n",
       "      <td>0.031951</td>\n",
       "      <td>0.900805</td>\n",
       "      <td>0.038689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(50, 50, 25)</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.890036</td>\n",
       "      <td>0.043926</td>\n",
       "      <td>0.875755</td>\n",
       "      <td>0.056516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(64, 32, 16, 8)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.875710</td>\n",
       "      <td>0.088929</td>\n",
       "      <td>0.847233</td>\n",
       "      <td>0.126471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.873860</td>\n",
       "      <td>0.034109</td>\n",
       "      <td>0.865342</td>\n",
       "      <td>0.045031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.873860</td>\n",
       "      <td>0.034109</td>\n",
       "      <td>0.865342</td>\n",
       "      <td>0.045031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(50, 25, 12, 6)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.852408</td>\n",
       "      <td>0.027335</td>\n",
       "      <td>0.847636</td>\n",
       "      <td>0.017399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.621607</td>\n",
       "      <td>0.259794</td>\n",
       "      <td>0.649044</td>\n",
       "      <td>0.139141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(50, 50, 25)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.607705</td>\n",
       "      <td>0.192655</td>\n",
       "      <td>0.606288</td>\n",
       "      <td>0.146113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(100, 50)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.596185</td>\n",
       "      <td>0.233571</td>\n",
       "      <td>0.599296</td>\n",
       "      <td>0.124430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(64, 32)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.567968</td>\n",
       "      <td>0.142472</td>\n",
       "      <td>0.521831</td>\n",
       "      <td>0.138978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(64, 32)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.369352</td>\n",
       "      <td>0.148660</td>\n",
       "      <td>0.450604</td>\n",
       "      <td>0.057822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.165094</td>\n",
       "      <td>0.285952</td>\n",
       "      <td>0.496479</td>\n",
       "      <td>0.003521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               layers activation solver    F1-avg    F1-std   Acc-avg  \\\n",
       "0               (64,)       relu  lbfgs  0.948611  0.024335  0.946982   \n",
       "1           (128, 64)       relu  lbfgs  0.948016  0.025126  0.946982   \n",
       "2       (128, 64, 32)       relu  lbfgs  0.947533  0.012610  0.946881   \n",
       "3            (64, 32)       tanh  lbfgs  0.942317  0.025546  0.939839   \n",
       "4   (100, 50, 25, 10)       relu  lbfgs  0.941314  0.019783  0.939839   \n",
       "5        (50, 25, 12)       relu  lbfgs  0.923420  0.015080  0.918511   \n",
       "6        (50, 25, 12)       tanh  lbfgs  0.908602  0.054756  0.904276   \n",
       "7        (50, 25, 12)       tanh  lbfgs  0.908602  0.054756  0.904276   \n",
       "8     (50, 25, 12, 6)       relu   adam  0.908277  0.031951  0.900805   \n",
       "9        (50, 50, 25)       relu   adam  0.890036  0.043926  0.875755   \n",
       "10    (64, 32, 16, 8)       relu  lbfgs  0.875710  0.088929  0.847233   \n",
       "11       (50, 25, 12)       relu   adam  0.873860  0.034109  0.865342   \n",
       "12       (50, 25, 12)       relu   adam  0.873860  0.034109  0.865342   \n",
       "13    (50, 25, 12, 6)       relu  lbfgs  0.852408  0.027335  0.847636   \n",
       "14       (50, 25, 12)       tanh   adam  0.621607  0.259794  0.649044   \n",
       "15       (50, 50, 25)       tanh   adam  0.607705  0.192655  0.606288   \n",
       "16          (100, 50)       tanh   adam  0.596185  0.233571  0.599296   \n",
       "17           (64, 32)       tanh   adam  0.567968  0.142472  0.521831   \n",
       "18           (64, 32)       tanh    sgd  0.369352  0.148660  0.450604   \n",
       "19       (50, 25, 12)   logistic   adam  0.165094  0.285952  0.496479   \n",
       "\n",
       "     Acc-std  \n",
       "0   0.024949  \n",
       "1   0.024949  \n",
       "2   0.011406  \n",
       "3   0.027063  \n",
       "4   0.020646  \n",
       "5   0.018011  \n",
       "6   0.059091  \n",
       "7   0.059091  \n",
       "8   0.038689  \n",
       "9   0.056516  \n",
       "10  0.126471  \n",
       "11  0.045031  \n",
       "12  0.045031  \n",
       "13  0.017399  \n",
       "14  0.139141  \n",
       "15  0.146113  \n",
       "16  0.124430  \n",
       "17  0.138978  \n",
       "18  0.057822  \n",
       "19  0.003521  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------\n",
    "# 📦 1. 导入依赖库\n",
    "# --------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE  # 可替换为 ADASYN\n",
    "\n",
    "# --------------------------------\n",
    "# 📂 2. 加载训练数据\n",
    "# --------------------------------\n",
    "df = pd.read_csv(\"../data/train_robot_v1.csv\")  # 或 sorted/scaled 文件\n",
    "X = df.drop(columns=[\"Target\"])\n",
    "y = df[\"Target\"]\n",
    "\n",
    "# --------------------------------\n",
    "# 🔄 3. 归一化处理\n",
    "# --------------------------------\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# --------------------------------\n",
    "# ⚖️ 4. 平衡样本（使用 SMOTE）\n",
    "# --------------------------------\n",
    "smote = SMOTE(random_state=42)\n",
    "X_bal, y_bal = smote.fit_resample(X, y)\n",
    "\n",
    "# --------------------------------\n",
    "# ⚙️ 5. 多组结构组合配置 config_list\n",
    "# --------------------------------\n",
    "config_list = [\n",
    "    {\"layers\": (50, 25, 12),         \"activation\": \"relu\",    \"solver\": \"adam\"},\n",
    "    {\"layers\": (50, 25, 12),         \"activation\": \"tanh\",    \"solver\": \"adam\"},\n",
    "    {\"layers\": (50, 25, 12),         \"activation\": \"logistic\",\"solver\": \"adam\"},\n",
    "    {\"layers\": (50, 25, 12),         \"activation\": \"relu\",    \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (50, 25, 12),         \"activation\": \"tanh\",    \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (64,),                \"activation\": \"relu\",    \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (128, 64),            \"activation\": \"relu\",    \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (100, 50, 25, 10),    \"activation\": \"relu\",    \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (64, 32, 16, 8),      \"activation\": \"relu\",    \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (50, 25, 12, 6),      \"activation\": \"relu\",    \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (64, 32),             \"activation\": \"tanh\",    \"solver\": \"adam\"},\n",
    "    {\"layers\": (64, 32),             \"activation\": \"tanh\",    \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (64, 32),             \"activation\": \"tanh\",    \"solver\": \"sgd\"},\n",
    "    {\"layers\": (50, 50, 25),         \"activation\": \"relu\",    \"solver\": \"adam\"},\n",
    "    {\"layers\": (50, 50, 25),         \"activation\": \"tanh\",    \"solver\": \"adam\"},\n",
    "    {\"layers\": (100, 50),            \"activation\": \"tanh\",    \"solver\": \"adam\"},\n",
    "    {\"layers\": (128, 64, 32),        \"activation\": \"relu\",    \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (50, 25, 12),         \"activation\": \"tanh\",    \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (50, 25, 12),         \"activation\": \"relu\",    \"solver\": \"adam\"},\n",
    "    {\"layers\": (50, 25, 12, 6),      \"activation\": \"relu\",    \"solver\": \"adam\"},\n",
    "]\n",
    "\n",
    "# --------------------------------\n",
    "# 🧪 6. 批量训练每组参数配置\n",
    "# --------------------------------\n",
    "results = []\n",
    "\n",
    "for cfg in config_list:\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=cfg[\"layers\"],\n",
    "        activation=cfg[\"activation\"],\n",
    "        solver=cfg[\"solver\"],\n",
    "        max_iter=500,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    scores = cross_validate(model, X_bal, y_bal, cv=4, scoring={\"f1\": \"f1\", \"accuracy\": \"accuracy\"})\n",
    "    \n",
    "    results.append({\n",
    "        \"layers\": cfg[\"layers\"],\n",
    "        \"activation\": cfg[\"activation\"],\n",
    "        \"solver\": cfg[\"solver\"],\n",
    "        \"F1-avg\": scores[\"test_f1\"].mean(),\n",
    "        \"F1-std\": scores[\"test_f1\"].std(),\n",
    "        \"Acc-avg\": scores[\"test_accuracy\"].mean(),\n",
    "        \"Acc-std\": scores[\"test_accuracy\"].std()\n",
    "    })\n",
    "\n",
    "# --------------------------------\n",
    "# 📊 7. 显示结果表格\n",
    "# --------------------------------\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results.sort_values(by=\"F1-avg\", ascending=False).reset_index(drop=True)\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "layers",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "activation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "solver",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "F1-avg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1-std",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Acc-avg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Acc-std",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "2d5c870c-55cd-4bb1-8a9f-848e03ce4e2f",
       "rows": [
        [
         "0",
         "(100, 50, 25, 10)",
         "relu",
         "lbfgs",
         "0.958729608773925",
         "0.024107909751126144",
         "0.9571428571428572",
         "0.026726124191242463"
        ],
        [
         "1",
         "(128, 64)",
         "relu",
         "lbfgs",
         "0.9514699739544941",
         "0.021564857697421076",
         "0.9500000000000001",
         "0.02369017707396715"
        ],
        [
         "2",
         "(50, 25, 12)",
         "relu",
         "lbfgs",
         "0.9383363311180213",
         "0.02719712453258392",
         "0.9357142857142857",
         "0.02945075446869758"
        ],
        [
         "3",
         "(64,)",
         "relu",
         "lbfgs",
         "0.9316269841269842",
         "0.02537036692211331",
         "0.9285714285714286",
         "0.026726124191242432"
        ],
        [
         "4",
         "(50, 25, 12)",
         "tanh",
         "lbfgs",
         "0.926622635355512",
         "0.03382776051684797",
         "0.925",
         "0.03406925719346235"
        ],
        [
         "5",
         "(50, 25, 12)",
         "tanh",
         "lbfgs",
         "0.926622635355512",
         "0.03382776051684797",
         "0.925",
         "0.03406925719346235"
        ],
        [
         "6",
         "(128, 64, 32)",
         "relu",
         "lbfgs",
         "0.9244534710062828",
         "0.03155452875473559",
         "0.925",
         "0.027432663385245054"
        ],
        [
         "7",
         "(64, 32)",
         "tanh",
         "lbfgs",
         "0.9233838383838383",
         "0.016017905882044523",
         "0.9178571428571428",
         "0.018557687223952245"
        ],
        [
         "8",
         "(64, 32, 16, 8)",
         "relu",
         "lbfgs",
         "0.9057890710712524",
         "0.03773298086572352",
         "0.8964285714285714",
         "0.04883855118277622"
        ],
        [
         "9",
         "(50, 50, 25)",
         "relu",
         "adam",
         "0.8507757368202573",
         "0.03143168793517721",
         "0.8535714285714286",
         "0.021128856368212882"
        ],
        [
         "10",
         "(50, 25, 12)",
         "relu",
         "adam",
         "0.8320074002869702",
         "0.06707037928727634",
         "0.8357142857142857",
         "0.05578749768504753"
        ],
        [
         "11",
         "(50, 25, 12)",
         "relu",
         "adam",
         "0.8320074002869702",
         "0.06707037928727634",
         "0.8357142857142857",
         "0.05578749768504753"
        ],
        [
         "12",
         "(50, 25, 12, 6)",
         "relu",
         "lbfgs",
         "0.8024988812172356",
         "0.090343918036823",
         "0.7892857142857143",
         "0.10320130911999918"
        ],
        [
         "13",
         "(50, 25, 12, 6)",
         "relu",
         "adam",
         "0.7940916667224494",
         "0.027768826996164817",
         "0.7714285714285714",
         "0.058901508937395174"
        ],
        [
         "14",
         "(50, 25, 12)",
         "tanh",
         "adam",
         "0.6996163081317816",
         "0.20685043072861498",
         "0.6678571428571428",
         "0.20858488214926915"
        ],
        [
         "15",
         "(64, 32)",
         "tanh",
         "adam",
         "0.607508212436186",
         "0.1070108832761989",
         "0.5321428571428571",
         "0.1415565798757601"
        ],
        [
         "16",
         "(50, 50, 25)",
         "tanh",
         "adam",
         "0.5563364108217353",
         "0.20066461898202753",
         "0.5321428571428571",
         "0.23891228857606522"
        ],
        [
         "17",
         "(64, 32)",
         "tanh",
         "sgd",
         "0.5391624260421711",
         "0.09582206599810028",
         "0.5",
         "0.017496355305594135"
        ],
        [
         "18",
         "(50, 25, 12)",
         "logistic",
         "adam",
         "0.4967948717948718",
         "0.2868724033527645",
         "0.49642857142857144",
         "0.006185895741317421"
        ],
        [
         "19",
         "(100, 50)",
         "tanh",
         "adam",
         "0.32450980392156864",
         "0.3255772975827227",
         "0.4107142857142857",
         "0.1267228214229298"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layers</th>\n",
       "      <th>activation</th>\n",
       "      <th>solver</th>\n",
       "      <th>F1-avg</th>\n",
       "      <th>F1-std</th>\n",
       "      <th>Acc-avg</th>\n",
       "      <th>Acc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(100, 50, 25, 10)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.958730</td>\n",
       "      <td>0.024108</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.026726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(128, 64)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.951470</td>\n",
       "      <td>0.021565</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.023690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.938336</td>\n",
       "      <td>0.027197</td>\n",
       "      <td>0.935714</td>\n",
       "      <td>0.029451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(64,)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.931627</td>\n",
       "      <td>0.025370</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.026726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.926623</td>\n",
       "      <td>0.033828</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.034069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.926623</td>\n",
       "      <td>0.033828</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.034069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(128, 64, 32)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.924453</td>\n",
       "      <td>0.031555</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.027433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(64, 32)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.923384</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>0.917857</td>\n",
       "      <td>0.018558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(64, 32, 16, 8)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.905789</td>\n",
       "      <td>0.037733</td>\n",
       "      <td>0.896429</td>\n",
       "      <td>0.048839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(50, 50, 25)</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.850776</td>\n",
       "      <td>0.031432</td>\n",
       "      <td>0.853571</td>\n",
       "      <td>0.021129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.832007</td>\n",
       "      <td>0.067070</td>\n",
       "      <td>0.835714</td>\n",
       "      <td>0.055787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.832007</td>\n",
       "      <td>0.067070</td>\n",
       "      <td>0.835714</td>\n",
       "      <td>0.055787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(50, 25, 12, 6)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.802499</td>\n",
       "      <td>0.090344</td>\n",
       "      <td>0.789286</td>\n",
       "      <td>0.103201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(50, 25, 12, 6)</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.794092</td>\n",
       "      <td>0.027769</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.058902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.699616</td>\n",
       "      <td>0.206850</td>\n",
       "      <td>0.667857</td>\n",
       "      <td>0.208585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(64, 32)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.607508</td>\n",
       "      <td>0.107011</td>\n",
       "      <td>0.532143</td>\n",
       "      <td>0.141557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(50, 50, 25)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.556336</td>\n",
       "      <td>0.200665</td>\n",
       "      <td>0.532143</td>\n",
       "      <td>0.238912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(64, 32)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.539162</td>\n",
       "      <td>0.095822</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.017496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.496795</td>\n",
       "      <td>0.286872</td>\n",
       "      <td>0.496429</td>\n",
       "      <td>0.006186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(100, 50)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.324510</td>\n",
       "      <td>0.325577</td>\n",
       "      <td>0.410714</td>\n",
       "      <td>0.126723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               layers activation solver    F1-avg    F1-std   Acc-avg  \\\n",
       "0   (100, 50, 25, 10)       relu  lbfgs  0.958730  0.024108  0.957143   \n",
       "1           (128, 64)       relu  lbfgs  0.951470  0.021565  0.950000   \n",
       "2        (50, 25, 12)       relu  lbfgs  0.938336  0.027197  0.935714   \n",
       "3               (64,)       relu  lbfgs  0.931627  0.025370  0.928571   \n",
       "4        (50, 25, 12)       tanh  lbfgs  0.926623  0.033828  0.925000   \n",
       "5        (50, 25, 12)       tanh  lbfgs  0.926623  0.033828  0.925000   \n",
       "6       (128, 64, 32)       relu  lbfgs  0.924453  0.031555  0.925000   \n",
       "7            (64, 32)       tanh  lbfgs  0.923384  0.016018  0.917857   \n",
       "8     (64, 32, 16, 8)       relu  lbfgs  0.905789  0.037733  0.896429   \n",
       "9        (50, 50, 25)       relu   adam  0.850776  0.031432  0.853571   \n",
       "10       (50, 25, 12)       relu   adam  0.832007  0.067070  0.835714   \n",
       "11       (50, 25, 12)       relu   adam  0.832007  0.067070  0.835714   \n",
       "12    (50, 25, 12, 6)       relu  lbfgs  0.802499  0.090344  0.789286   \n",
       "13    (50, 25, 12, 6)       relu   adam  0.794092  0.027769  0.771429   \n",
       "14       (50, 25, 12)       tanh   adam  0.699616  0.206850  0.667857   \n",
       "15           (64, 32)       tanh   adam  0.607508  0.107011  0.532143   \n",
       "16       (50, 50, 25)       tanh   adam  0.556336  0.200665  0.532143   \n",
       "17           (64, 32)       tanh    sgd  0.539162  0.095822  0.500000   \n",
       "18       (50, 25, 12)   logistic   adam  0.496795  0.286872  0.496429   \n",
       "19          (100, 50)       tanh   adam  0.324510  0.325577  0.410714   \n",
       "\n",
       "     Acc-std  \n",
       "0   0.026726  \n",
       "1   0.023690  \n",
       "2   0.029451  \n",
       "3   0.026726  \n",
       "4   0.034069  \n",
       "5   0.034069  \n",
       "6   0.027433  \n",
       "7   0.018558  \n",
       "8   0.048839  \n",
       "9   0.021129  \n",
       "10  0.055787  \n",
       "11  0.055787  \n",
       "12  0.103201  \n",
       "13  0.058902  \n",
       "14  0.208585  \n",
       "15  0.141557  \n",
       "16  0.238912  \n",
       "17  0.017496  \n",
       "18  0.006186  \n",
       "19  0.126723  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------\n",
    "# 📦 1. 导入依赖\n",
    "# --------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import ADASYN  # ✅ 使用 ADASYN\n",
    "\n",
    "# --------------------------------\n",
    "# 📂 2. 加载训练数据\n",
    "# --------------------------------\n",
    "df = pd.read_csv(\"../data/train_robot_v1.csv\")  # 也可换成 sorted/scaled 文件\n",
    "X = df.drop(columns=[\"Target\"])\n",
    "y = df[\"Target\"]\n",
    "\n",
    "# --------------------------------\n",
    "# 🔄 3. 归一化\n",
    "# --------------------------------\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# --------------------------------\n",
    "# ⚖️ 4. 使用 ADASYN 进行平衡\n",
    "# --------------------------------\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_bal, y_bal = adasyn.fit_resample(X, y)\n",
    "\n",
    "# --------------------------------\n",
    "# ⚙️ 5. 模型结构组合列表\n",
    "# --------------------------------\n",
    "config_list = [\n",
    "    {\"layers\": (50, 25, 12),         \"activation\": \"relu\",    \"solver\": \"adam\"},\n",
    "    {\"layers\": (50, 25, 12),         \"activation\": \"tanh\",    \"solver\": \"adam\"},\n",
    "    {\"layers\": (50, 25, 12),         \"activation\": \"logistic\",\"solver\": \"adam\"},\n",
    "    {\"layers\": (50, 25, 12),         \"activation\": \"relu\",    \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (50, 25, 12),         \"activation\": \"tanh\",    \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (64,),                \"activation\": \"relu\",    \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (128, 64),            \"activation\": \"relu\",    \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (100, 50, 25, 10),    \"activation\": \"relu\",    \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (64, 32, 16, 8),      \"activation\": \"relu\",    \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (50, 25, 12, 6),      \"activation\": \"relu\",    \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (64, 32),             \"activation\": \"tanh\",    \"solver\": \"adam\"},\n",
    "    {\"layers\": (64, 32),             \"activation\": \"tanh\",    \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (64, 32),             \"activation\": \"tanh\",    \"solver\": \"sgd\"},\n",
    "    {\"layers\": (50, 50, 25),         \"activation\": \"relu\",    \"solver\": \"adam\"},\n",
    "    {\"layers\": (50, 50, 25),         \"activation\": \"tanh\",    \"solver\": \"adam\"},\n",
    "    {\"layers\": (100, 50),            \"activation\": \"tanh\",    \"solver\": \"adam\"},\n",
    "    {\"layers\": (128, 64, 32),        \"activation\": \"relu\",    \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (50, 25, 12),         \"activation\": \"tanh\",    \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (50, 25, 12),         \"activation\": \"relu\",    \"solver\": \"adam\"},\n",
    "    {\"layers\": (50, 25, 12, 6),      \"activation\": \"relu\",    \"solver\": \"adam\"},\n",
    "]\n",
    "\n",
    "# --------------------------------\n",
    "# 🧪 6. 批量评估模型\n",
    "# --------------------------------\n",
    "results = []\n",
    "\n",
    "for cfg in config_list:\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=cfg[\"layers\"],\n",
    "        activation=cfg[\"activation\"],\n",
    "        solver=cfg[\"solver\"],\n",
    "        max_iter=500,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    scores = cross_validate(model, X_bal, y_bal, cv=4, scoring={\"f1\": \"f1\", \"accuracy\": \"accuracy\"})\n",
    "    \n",
    "    results.append({\n",
    "        \"layers\": cfg[\"layers\"],\n",
    "        \"activation\": cfg[\"activation\"],\n",
    "        \"solver\": cfg[\"solver\"],\n",
    "        \"F1-avg\": scores[\"test_f1\"].mean(),\n",
    "        \"F1-std\": scores[\"test_f1\"].std(),\n",
    "        \"Acc-avg\": scores[\"test_accuracy\"].mean(),\n",
    "        \"Acc-std\": scores[\"test_accuracy\"].std()\n",
    "    })\n",
    "\n",
    "# --------------------------------\n",
    "# 📊 7. 输出对比表格\n",
    "# --------------------------------\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results.sort_values(by=\"F1-avg\", ascending=False).reset_index(drop=True)\n",
    "df_results.head(20)  # 显示前10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "dump() missing 1 required positional argument: 'filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m X_bal, y_bal = adasyn.fit_resample(X_scaled, y)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# ✅ 保存 scaler（可选）\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../models/minmax_scaler.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# --------------------------------\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# 🧠 3. 构建最佳模型\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# --------------------------------\u001b[39;00m\n\u001b[32m     34\u001b[39m model = MLPClassifier(\n\u001b[32m     35\u001b[39m     hidden_layer_sizes=(\u001b[32m128\u001b[39m, \u001b[32m64\u001b[39m, \u001b[32m32\u001b[39m),  \u001b[38;5;66;03m# 你选定的结构\u001b[39;00m\n\u001b[32m     36\u001b[39m     activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m     40\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: dump() missing 1 required positional argument: 'filename'"
     ]
    }
   ],
   "source": [
    "# --------------------------------\n",
    "# 📦 1. 导入必要的库\n",
    "# --------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import ADASYN\n",
    "import joblib  # ✅ 用于保存模型\n",
    "\n",
    "# --------------------------------\n",
    "# 📂 2. 加载排序后的训练集（归一化版本）\n",
    "# --------------------------------\n",
    "df = pd.read_csv(\"../data/train_robot_sorted_v1.csv\")\n",
    "X = df.drop(columns=[\"Target\"])\n",
    "y = df[\"Target\"]\n",
    "\n",
    "# ✅ 归一化（和之前一致，保持一致性）\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ✅ 使用 ADASYN 平衡数据\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_bal, y_bal = adasyn.fit_resample(X_scaled, y)\n",
    "\n",
    "# ✅ 保存 scaler（可选）\n",
    "joblib.dump(scaler, \"../models/minmax_scaler.pkl\")\n",
    "\n",
    "# --------------------------------\n",
    "# 🧠 3. 构建最佳模型\n",
    "# --------------------------------\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64, 32),  # 你选定的结构\n",
    "    activation='relu',\n",
    "    solver='lbfgs',\n",
    "    max_iter=500,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_bal, y_bal)\n",
    "\n",
    "# ✅ 保存模型\n",
    "joblib.dump(model, \"../models/best_model_adasyn.pkl\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
