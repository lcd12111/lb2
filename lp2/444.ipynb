{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37e9b973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HUAWEI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Unbalanced Data\n",
      "F1-score (avg): 0.5798373983739837  std: 0.1863210306764588\n",
      "Accuracy (avg): 0.7102272727272727  std: 0.22289824143105716\n",
      "\n",
      "📊 SMOTE Balanced\n",
      "F1-score (avg): 0.8650290842742188  std: 0.07453295963757665\n",
      "Accuracy (avg): 0.8357142857142856  std: 0.10177004891982147\n",
      "\n",
      "📊 ADASYN Balanced\n",
      "F1-score (avg): 0.8143575741850262  std: 0.06984932620983558\n",
      "Accuracy (avg): 0.7760060362173038  std: 0.09433309031721646\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# --------------------------------\n",
    "# 📂 2. 加载归一化数据\n",
    "# --------------------------------\n",
    "# 修改点：读取用户提供的sorted_data.csv文件\n",
    "df = pd.read_csv(\"sorted_data.csv\")  # 替换为实际数据文件路径\n",
    "\n",
    "# ----------------------------\n",
    "# 2. 特征/目标分离（保持原始逻辑）\n",
    "# ----------------------------\n",
    "# 修改点：将type=5转换为二分类目标\n",
    "X = df.drop(columns=[\"Type\"])  # 假设特征列不包含type列\n",
    "y = (df[\"Type\"] == 5).astype(int)  # 将type=5转为1，其他转为0\n",
    "\n",
    "# 可选：MinMaxScaler 再次确认归一化\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# --------------------------------\n",
    "# 🧠 3. 定义模型结构（使用最佳结构）\n",
    "# --------------------------------\n",
    "def get_model():\n",
    "    return MLPClassifier(\n",
    "        hidden_layer_sizes=(64,),\n",
    "        activation='relu',\n",
    "        solver='lbfgs',\n",
    "        max_iter=500,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "# --------------------------------\n",
    "# ⚖️ 4. 定义评估函数\n",
    "# --------------------------------\n",
    "def evaluate(X, y, title):\n",
    "    model = get_model()\n",
    "    scores = cross_validate(model, X, y, cv=4, scoring={\"f1\": \"f1\", \"accuracy\": \"accuracy\"})\n",
    "    print(f\"\\n📊 {title}\")\n",
    "    print(\"F1-score (avg):\", scores['test_f1'].mean(), \" std:\", scores['test_f1'].std())\n",
    "    print(\"Accuracy (avg):\", scores['test_accuracy'].mean(), \" std:\", scores['test_accuracy'].std())\n",
    "    return scores\n",
    "\n",
    "# --------------------------------\n",
    "# ✅ 5. 原始不平衡数据评估\n",
    "# --------------------------------\n",
    "raw_scores = evaluate(X, y, \"Unbalanced Data\")\n",
    "\n",
    "# --------------------------------\n",
    "# ⚙️ 6. SMOTE 平衡\n",
    "# --------------------------------\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)\n",
    "smote_scores = evaluate(X_smote, y_smote, \"SMOTE Balanced\")\n",
    "\n",
    "# --------------------------------\n",
    "# ⚙️ 7. ADASYN 平衡\n",
    "# --------------------------------\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_ada, y_ada = adasyn.fit_resample(X, y)\n",
    "adasyn_scores = evaluate(X_ada, y_ada, \"ADASYN Balanced\")\n",
    "\n",
    "# --------------------------------\n",
    "# 📈 8. 可视化对比\n",
    "# --------------------------------\n",
    "labels = ['Raw', 'SMOTE', 'ADASYN']\n",
    "f1_avgs = [raw_scores['test_f1'].mean(), smote_scores['test_f1'].mean(), adasyn_scores['test_f1'].mean()]\n",
    "acc_avgs = [raw_scores['test_accuracy'].mean(), smote_scores['test_accuracy'].mean(), adasyn_scores['test_accuracy'].mean()]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(labels, f1_avgs, alpha=0.7, label=\"F1-score\")\n",
    "plt.bar(labels, acc_avgs, alpha=0.7, label=\"Accuracy\", bottom=f1_avgs)\n",
    "plt.title(\"Comparison: Raw vs SMOTE vs ADASYN (Type=5)\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47cd4142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HUAWEI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\HUAWEI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\HUAWEI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\HUAWEI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\HUAWEI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\HUAWEI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "layers",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "activation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "solver",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "F1-avg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1-std",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Acc-avg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Acc-std",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "bb5ab968-608f-4f9b-becb-a98382750922",
       "rows": [
        [
         "0",
         "(128, 64)",
         "relu",
         "lbfgs",
         "0.9526014027726357",
         "0.014493569906828882",
         "0.95",
         "0.01597191412499849"
        ],
        [
         "1",
         "(50, 25, 12)",
         "relu",
         "lbfgs",
         "0.9479497102736539",
         "0.02893273918235491",
         "0.9464285714285715",
         "0.02923340275668731"
        ],
        [
         "2",
         "(100, 50, 25, 10)",
         "relu",
         "lbfgs",
         "0.9432112685537343",
         "0.020397352216836234",
         "0.9392857142857143",
         "0.023419423301078577"
        ],
        [
         "3",
         "(128, 64, 32)",
         "relu",
         "lbfgs",
         "0.9275121275121274",
         "0.018111861804318948",
         "0.9214285714285715",
         "0.021428571428571446"
        ],
        [
         "4",
         "(64,)",
         "relu",
         "lbfgs",
         "0.923998613998614",
         "0.022188651765718933",
         "0.9178571428571429",
         "0.02550510153051018"
        ],
        [
         "5",
         "(50, 25, 12)",
         "tanh",
         "lbfgs",
         "0.918635073429594",
         "0.040351795015201176",
         "0.9142857142857144",
         "0.04164965639175214"
        ],
        [
         "6",
         "(50, 25, 12)",
         "tanh",
         "lbfgs",
         "0.918635073429594",
         "0.040351795015201176",
         "0.9142857142857144",
         "0.04164965639175214"
        ],
        [
         "7",
         "(64, 32, 16, 8)",
         "relu",
         "lbfgs",
         "0.9174763143425115",
         "0.04787247644653296",
         "0.9142857142857143",
         "0.048445214165180474"
        ],
        [
         "8",
         "(50, 25, 12, 6)",
         "relu",
         "lbfgs",
         "0.905886621189433",
         "0.04086649328223559",
         "0.8964285714285715",
         "0.04670248868079292"
        ],
        [
         "9",
         "(64, 32)",
         "tanh",
         "lbfgs",
         "0.898261519347462",
         "0.023993198202161756",
         "0.8892857142857142",
         "0.025505101530510176"
        ],
        [
         "10",
         "(50, 25, 12, 6)",
         "relu",
         "adam",
         "0.8965616676661426",
         "0.0447446520935094",
         "0.8892857142857143",
         "0.04670248868079293"
        ],
        [
         "11",
         "(50, 25, 12)",
         "relu",
         "adam",
         "0.8811847675195805",
         "0.028708421768347203",
         "0.8678571428571429",
         "0.03694314440281642"
        ],
        [
         "12",
         "(50, 25, 12)",
         "relu",
         "adam",
         "0.8811847675195805",
         "0.028708421768347203",
         "0.8678571428571429",
         "0.03694314440281642"
        ],
        [
         "13",
         "(50, 50, 25)",
         "tanh",
         "adam",
         "0.8784046948603911",
         "0.0433200010057889",
         "0.8642857142857143",
         "0.04999999999999998"
        ],
        [
         "14",
         "(50, 50, 25)",
         "relu",
         "adam",
         "0.872921793653501",
         "0.02196316674958325",
         "0.8571428571428571",
         "0.026726124191242432"
        ],
        [
         "15",
         "(50, 25, 12)",
         "tanh",
         "adam",
         "0.7201016043868151",
         "0.22202903746731706",
         "0.7607142857142858",
         "0.12631956559876711"
        ],
        [
         "16",
         "(64, 32)",
         "tanh",
         "adam",
         "0.6179866299002561",
         "0.15202867558897853",
         "0.6392857142857142",
         "0.07913757073628692"
        ],
        [
         "17",
         "(100, 50)",
         "tanh",
         "adam",
         "0.5343767429680742",
         "0.1988903865998446",
         "0.6071428571428572",
         "0.11539638872431082"
        ],
        [
         "18",
         "(64, 32)",
         "tanh",
         "sgd",
         "0.5280269004153386",
         "0.05809948142324057",
         "0.5178571428571428",
         "0.04087686836521283"
        ],
        [
         "19",
         "(50, 25, 12)",
         "logistic",
         "adam",
         "0.16666666666666666",
         "0.2886751345948129",
         "0.5",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layers</th>\n",
       "      <th>activation</th>\n",
       "      <th>solver</th>\n",
       "      <th>F1-avg</th>\n",
       "      <th>F1-std</th>\n",
       "      <th>Acc-avg</th>\n",
       "      <th>Acc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(128, 64)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.952601</td>\n",
       "      <td>0.014494</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.015972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.947950</td>\n",
       "      <td>0.028933</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.029233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(100, 50, 25, 10)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.943211</td>\n",
       "      <td>0.020397</td>\n",
       "      <td>0.939286</td>\n",
       "      <td>0.023419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(128, 64, 32)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.927512</td>\n",
       "      <td>0.018112</td>\n",
       "      <td>0.921429</td>\n",
       "      <td>0.021429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(64,)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.923999</td>\n",
       "      <td>0.022189</td>\n",
       "      <td>0.917857</td>\n",
       "      <td>0.025505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.918635</td>\n",
       "      <td>0.040352</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.041650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.918635</td>\n",
       "      <td>0.040352</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.041650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(64, 32, 16, 8)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.917476</td>\n",
       "      <td>0.047872</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.048445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(50, 25, 12, 6)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.905887</td>\n",
       "      <td>0.040866</td>\n",
       "      <td>0.896429</td>\n",
       "      <td>0.046702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(64, 32)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.898262</td>\n",
       "      <td>0.023993</td>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.025505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(50, 25, 12, 6)</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.896562</td>\n",
       "      <td>0.044745</td>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.046702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.881185</td>\n",
       "      <td>0.028708</td>\n",
       "      <td>0.867857</td>\n",
       "      <td>0.036943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.881185</td>\n",
       "      <td>0.028708</td>\n",
       "      <td>0.867857</td>\n",
       "      <td>0.036943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(50, 50, 25)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.878405</td>\n",
       "      <td>0.043320</td>\n",
       "      <td>0.864286</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(50, 50, 25)</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.872922</td>\n",
       "      <td>0.021963</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.026726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.720102</td>\n",
       "      <td>0.222029</td>\n",
       "      <td>0.760714</td>\n",
       "      <td>0.126320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(64, 32)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.617987</td>\n",
       "      <td>0.152029</td>\n",
       "      <td>0.639286</td>\n",
       "      <td>0.079138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(100, 50)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.534377</td>\n",
       "      <td>0.198890</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.115396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(64, 32)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.528027</td>\n",
       "      <td>0.058099</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>0.040877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               layers activation solver    F1-avg    F1-std   Acc-avg  \\\n",
       "0           (128, 64)       relu  lbfgs  0.952601  0.014494  0.950000   \n",
       "1        (50, 25, 12)       relu  lbfgs  0.947950  0.028933  0.946429   \n",
       "2   (100, 50, 25, 10)       relu  lbfgs  0.943211  0.020397  0.939286   \n",
       "3       (128, 64, 32)       relu  lbfgs  0.927512  0.018112  0.921429   \n",
       "4               (64,)       relu  lbfgs  0.923999  0.022189  0.917857   \n",
       "5        (50, 25, 12)       tanh  lbfgs  0.918635  0.040352  0.914286   \n",
       "6        (50, 25, 12)       tanh  lbfgs  0.918635  0.040352  0.914286   \n",
       "7     (64, 32, 16, 8)       relu  lbfgs  0.917476  0.047872  0.914286   \n",
       "8     (50, 25, 12, 6)       relu  lbfgs  0.905887  0.040866  0.896429   \n",
       "9            (64, 32)       tanh  lbfgs  0.898262  0.023993  0.889286   \n",
       "10    (50, 25, 12, 6)       relu   adam  0.896562  0.044745  0.889286   \n",
       "11       (50, 25, 12)       relu   adam  0.881185  0.028708  0.867857   \n",
       "12       (50, 25, 12)       relu   adam  0.881185  0.028708  0.867857   \n",
       "13       (50, 50, 25)       tanh   adam  0.878405  0.043320  0.864286   \n",
       "14       (50, 50, 25)       relu   adam  0.872922  0.021963  0.857143   \n",
       "15       (50, 25, 12)       tanh   adam  0.720102  0.222029  0.760714   \n",
       "16           (64, 32)       tanh   adam  0.617987  0.152029  0.639286   \n",
       "17          (100, 50)       tanh   adam  0.534377  0.198890  0.607143   \n",
       "18           (64, 32)       tanh    sgd  0.528027  0.058099  0.517857   \n",
       "19       (50, 25, 12)   logistic   adam  0.166667  0.288675  0.500000   \n",
       "\n",
       "     Acc-std  \n",
       "0   0.015972  \n",
       "1   0.029233  \n",
       "2   0.023419  \n",
       "3   0.021429  \n",
       "4   0.025505  \n",
       "5   0.041650  \n",
       "6   0.041650  \n",
       "7   0.048445  \n",
       "8   0.046702  \n",
       "9   0.025505  \n",
       "10  0.046702  \n",
       "11  0.036943  \n",
       "12  0.036943  \n",
       "13  0.050000  \n",
       "14  0.026726  \n",
       "15  0.126320  \n",
       "16  0.079138  \n",
       "17  0.115396  \n",
       "18  0.040877  \n",
       "19  0.000000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE  # 可替换为 ADASYN\n",
    "\n",
    "# --------------------------------\n",
    "# 📦 1. 导入依赖库\n",
    "# --------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE  # 可替换为 ADASYN\n",
    "\n",
    "# ----------------------------\n",
    "# 1. 加载数据（使用用户提供的sorted_data.csv）\n",
    "# ----------------------------\n",
    "train_data = pd.read_excel('Data_Set_(A+B).xlsx')\n",
    "\n",
    "# ----------------------------\n",
    "# 2. 特征/目标分离（保持原始逻辑）\n",
    "# ----------------------------\n",
    "# 修改点：将type=5转换为二分类目标\n",
    "X = train_data.drop(columns=[\"Type\"])  # 假设特征列不包含type列\n",
    "y = (train_data[\"Type\"] == 5).astype(int)  # 将type=5转为1，其他转为0\n",
    "\n",
    "# --------------------------------\n",
    "# 🔄 3. 归一化处理\n",
    "# --------------------------------\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# --------------------------------\n",
    "# ⚖️ 4. 平衡样本（使用 SMOTE）\n",
    "# --------------------------------\n",
    "smote = SMOTE(random_state=42)\n",
    "X_bal, y_bal = smote.fit_resample(X, y)\n",
    "\n",
    "# --------------------------------\n",
    "# ⚙️ 5. 多组结构组合配置 config_list\n",
    "# --------------------------------\n",
    "config_list = config_list = [\n",
    "    # 原始配置组\n",
    "    {\"layers\": (50, 25, 12), \"activation\": \"relu\", \"solver\": \"adam\"},\n",
    "    {\"layers\": (50, 25, 12), \"activation\": \"tanh\", \"solver\": \"adam\"},\n",
    "    {\"layers\": (50, 25, 12), \"activation\": \"logistic\", \"solver\": \"adam\"},\n",
    "    {\"layers\": (50, 25, 12), \"activation\": \"relu\", \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (50, 25, 12), \"activation\": \"tanh\", \"solver\": \"lbfgs\"},\n",
    "    \n",
    "    # 扩展结构组\n",
    "    {\"layers\": (64,), \"activation\": \"relu\", \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (128, 64), \"activation\": \"relu\", \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (100, 50, 25, 10), \"activation\": \"relu\", \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (64, 32, 16, 8), \"activation\": \"relu\", \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (50, 25, 12, 6), \"activation\": \"relu\", \"solver\": \"lbfgs\"},\n",
    "    \n",
    "    # 混合配置组\n",
    "    {\"layers\": (64, 32), \"activation\": \"tanh\", \"solver\": \"adam\"},\n",
    "    {\"layers\": (64, 32), \"activation\": \"tanh\", \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (64, 32), \"activation\": \"tanh\", \"solver\": \"sgd\"},\n",
    "    \n",
    "    {\"layers\": (50, 50,25), \"activation\": \"relu\", \"solver\": \"adam\"},\n",
    "    {\"layers\": (50, 50,25), \"activation\": \"tanh\", \"solver\": \"adam\"},\n",
    "    {\"layers\": (100, 50), \"activation\": \"tanh\", \"solver\": \"adam\"},\n",
    "    {\"layers\": (128, 64, 32), \"activation\": \"relu\", \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (50, 25, 12), \"activation\": \"tanh\", \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (50, 25, 12), \"activation\": \"relu\", \"solver\": \"adam\"},\n",
    "    {\"layers\": (50, 25, 12,6), \"activation\": \"relu\", \"solver\": \"adam\"},\n",
    "]\n",
    "\n",
    "# --------------------------------\n",
    "# 🧪 6. 批量训练每组参数配置\n",
    "# --------------------------------\n",
    "results = []\n",
    "\n",
    "for cfg in config_list:\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=cfg[\"layers\"],\n",
    "        activation=cfg[\"activation\"],\n",
    "        solver=cfg[\"solver\"],\n",
    "        max_iter=500,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    scores = cross_validate(model, X_bal, y_bal, cv=4, scoring={\"f1\": \"f1\", \"accuracy\": \"accuracy\"})\n",
    "    \n",
    "    results.append({\n",
    "        \"layers\": cfg[\"layers\"],\n",
    "        \"activation\": cfg[\"activation\"],\n",
    "        \"solver\": cfg[\"solver\"],\n",
    "        \"F1-avg\": scores[\"test_f1\"].mean(),\n",
    "        \"F1-std\": scores[\"test_f1\"].std(),\n",
    "        \"Acc-avg\": scores[\"test_accuracy\"].mean(),\n",
    "        \"Acc-std\": scores[\"test_accuracy\"].std()\n",
    "    })\n",
    "\n",
    "# --------------------------------\n",
    "# 📊 7. 显示结果表格\n",
    "# --------------------------------\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results.sort_values(by=\"F1-avg\", ascending=False).reset_index(drop=True)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a0c7303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HUAWEI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\HUAWEI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\HUAWEI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\HUAWEI\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "layers",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "activation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "solver",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "F1-avg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F1-std",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Acc-avg",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Acc-std",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "4b42ef89-58a5-4218-84dc-7f08c27edc93",
       "rows": [
        [
         "0",
         "(64,)",
         "relu",
         "lbfgs",
         "0.9368833118833119",
         "0.04727142008193434",
         "0.9362173038229376",
         "0.04599555337078952"
        ],
        [
         "1",
         "(128, 64)",
         "relu",
         "lbfgs",
         "0.931462834230673",
         "0.055485933658704294",
         "0.9326961770623743",
         "0.050925807710109544"
        ],
        [
         "2",
         "(100, 50, 25, 10)",
         "relu",
         "lbfgs",
         "0.9292428169140498",
         "0.030500901251027956",
         "0.9289738430583501",
         "0.026082155897011412"
        ],
        [
         "3",
         "(50, 25, 12)",
         "relu",
         "lbfgs",
         "0.9060477709731442",
         "0.042653959384363976",
         "0.9041247484909456",
         "0.0374241416217386"
        ],
        [
         "4",
         "(64, 32, 16, 8)",
         "relu",
         "lbfgs",
         "0.9053549190535491",
         "0.06714396297239637",
         "0.9007545271629779",
         "0.06875466359349518"
        ],
        [
         "5",
         "(128, 64, 32)",
         "relu",
         "lbfgs",
         "0.9020448679769704",
         "0.06974221953919116",
         "0.900754527162978",
         "0.06571940733564605"
        ],
        [
         "6",
         "(64, 32)",
         "tanh",
         "lbfgs",
         "0.9020276146988476",
         "0.07594452126222503",
         "0.9008048289738431",
         "0.07353388419732254"
        ],
        [
         "7",
         "(50, 25, 12, 6)",
         "relu",
         "adam",
         "0.8872683469236472",
         "0.06662961563349401",
         "0.8793259557344064",
         "0.07081414184387434"
        ],
        [
         "8",
         "(50, 50, 25)",
         "relu",
         "adam",
         "0.8851806035033883",
         "0.07186542908657889",
         "0.8758551307847082",
         "0.07587660941903171"
        ],
        [
         "9",
         "(50, 25, 12)",
         "tanh",
         "lbfgs",
         "0.8834323334323335",
         "0.06691074653371479",
         "0.8793762575452717",
         "0.06375087273947419"
        ],
        [
         "10",
         "(50, 25, 12)",
         "tanh",
         "lbfgs",
         "0.8834323334323335",
         "0.06691074653371479",
         "0.8793762575452717",
         "0.06375087273947419"
        ],
        [
         "11",
         "(50, 25, 12)",
         "relu",
         "adam",
         "0.8574992129788932",
         "0.06094235087220952",
         "0.84738430583501",
         "0.0715670859188967"
        ],
        [
         "12",
         "(50, 25, 12)",
         "relu",
         "adam",
         "0.8574992129788932",
         "0.06094235087220952",
         "0.84738430583501",
         "0.0715670859188967"
        ],
        [
         "13",
         "(50, 25, 12, 6)",
         "relu",
         "lbfgs",
         "0.8509991158399971",
         "0.12948663500918411",
         "0.826609657947686",
         "0.16084907582896887"
        ],
        [
         "14",
         "(50, 25, 12)",
         "tanh",
         "adam",
         "0.7603766121925819",
         "0.19517463872489885",
         "0.7830482897384307",
         "0.14310760874181758"
        ],
        [
         "15",
         "(100, 50)",
         "tanh",
         "adam",
         "0.7024342122319878",
         "0.08396655704925275",
         "0.6730382293762576",
         "0.09742597259513705"
        ],
        [
         "16",
         "(64, 32)",
         "tanh",
         "adam",
         "0.5880970880970882",
         "0.15199217286389496",
         "0.6229879275653925",
         "0.1081413946209427"
        ],
        [
         "17",
         "(64, 32)",
         "tanh",
         "sgd",
         "0.5570280870445344",
         "0.15150178639536474",
         "0.5840543259557344",
         "0.10341087090612272"
        ],
        [
         "18",
         "(50, 25, 12)",
         "logistic",
         "adam",
         "0.4367816091954023",
         "0.27248895611792406",
         "0.5018108651911468",
         "0.007754966736660647"
        ],
        [
         "19",
         "(50, 50, 25)",
         "tanh",
         "adam",
         "0.2680779569892473",
         "0.20901858989106345",
         "0.5120221327967807",
         "0.07656290890896512"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layers</th>\n",
       "      <th>activation</th>\n",
       "      <th>solver</th>\n",
       "      <th>F1-avg</th>\n",
       "      <th>F1-std</th>\n",
       "      <th>Acc-avg</th>\n",
       "      <th>Acc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(64,)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.936883</td>\n",
       "      <td>0.047271</td>\n",
       "      <td>0.936217</td>\n",
       "      <td>0.045996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(128, 64)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.931463</td>\n",
       "      <td>0.055486</td>\n",
       "      <td>0.932696</td>\n",
       "      <td>0.050926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(100, 50, 25, 10)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.929243</td>\n",
       "      <td>0.030501</td>\n",
       "      <td>0.928974</td>\n",
       "      <td>0.026082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.906048</td>\n",
       "      <td>0.042654</td>\n",
       "      <td>0.904125</td>\n",
       "      <td>0.037424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(64, 32, 16, 8)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.905355</td>\n",
       "      <td>0.067144</td>\n",
       "      <td>0.900755</td>\n",
       "      <td>0.068755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(128, 64, 32)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.902045</td>\n",
       "      <td>0.069742</td>\n",
       "      <td>0.900755</td>\n",
       "      <td>0.065719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(64, 32)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.902028</td>\n",
       "      <td>0.075945</td>\n",
       "      <td>0.900805</td>\n",
       "      <td>0.073534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(50, 25, 12, 6)</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.887268</td>\n",
       "      <td>0.066630</td>\n",
       "      <td>0.879326</td>\n",
       "      <td>0.070814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(50, 50, 25)</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.885181</td>\n",
       "      <td>0.071865</td>\n",
       "      <td>0.875855</td>\n",
       "      <td>0.075877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.883432</td>\n",
       "      <td>0.066911</td>\n",
       "      <td>0.879376</td>\n",
       "      <td>0.063751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.883432</td>\n",
       "      <td>0.066911</td>\n",
       "      <td>0.879376</td>\n",
       "      <td>0.063751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.857499</td>\n",
       "      <td>0.060942</td>\n",
       "      <td>0.847384</td>\n",
       "      <td>0.071567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.857499</td>\n",
       "      <td>0.060942</td>\n",
       "      <td>0.847384</td>\n",
       "      <td>0.071567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(50, 25, 12, 6)</td>\n",
       "      <td>relu</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.850999</td>\n",
       "      <td>0.129487</td>\n",
       "      <td>0.826610</td>\n",
       "      <td>0.160849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.760377</td>\n",
       "      <td>0.195175</td>\n",
       "      <td>0.783048</td>\n",
       "      <td>0.143108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(100, 50)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.702434</td>\n",
       "      <td>0.083967</td>\n",
       "      <td>0.673038</td>\n",
       "      <td>0.097426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(64, 32)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.588097</td>\n",
       "      <td>0.151992</td>\n",
       "      <td>0.622988</td>\n",
       "      <td>0.108141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(64, 32)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.557028</td>\n",
       "      <td>0.151502</td>\n",
       "      <td>0.584054</td>\n",
       "      <td>0.103411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(50, 25, 12)</td>\n",
       "      <td>logistic</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.436782</td>\n",
       "      <td>0.272489</td>\n",
       "      <td>0.501811</td>\n",
       "      <td>0.007755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(50, 50, 25)</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.268078</td>\n",
       "      <td>0.209019</td>\n",
       "      <td>0.512022</td>\n",
       "      <td>0.076563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               layers activation solver    F1-avg    F1-std   Acc-avg  \\\n",
       "0               (64,)       relu  lbfgs  0.936883  0.047271  0.936217   \n",
       "1           (128, 64)       relu  lbfgs  0.931463  0.055486  0.932696   \n",
       "2   (100, 50, 25, 10)       relu  lbfgs  0.929243  0.030501  0.928974   \n",
       "3        (50, 25, 12)       relu  lbfgs  0.906048  0.042654  0.904125   \n",
       "4     (64, 32, 16, 8)       relu  lbfgs  0.905355  0.067144  0.900755   \n",
       "5       (128, 64, 32)       relu  lbfgs  0.902045  0.069742  0.900755   \n",
       "6            (64, 32)       tanh  lbfgs  0.902028  0.075945  0.900805   \n",
       "7     (50, 25, 12, 6)       relu   adam  0.887268  0.066630  0.879326   \n",
       "8        (50, 50, 25)       relu   adam  0.885181  0.071865  0.875855   \n",
       "9        (50, 25, 12)       tanh  lbfgs  0.883432  0.066911  0.879376   \n",
       "10       (50, 25, 12)       tanh  lbfgs  0.883432  0.066911  0.879376   \n",
       "11       (50, 25, 12)       relu   adam  0.857499  0.060942  0.847384   \n",
       "12       (50, 25, 12)       relu   adam  0.857499  0.060942  0.847384   \n",
       "13    (50, 25, 12, 6)       relu  lbfgs  0.850999  0.129487  0.826610   \n",
       "14       (50, 25, 12)       tanh   adam  0.760377  0.195175  0.783048   \n",
       "15          (100, 50)       tanh   adam  0.702434  0.083967  0.673038   \n",
       "16           (64, 32)       tanh   adam  0.588097  0.151992  0.622988   \n",
       "17           (64, 32)       tanh    sgd  0.557028  0.151502  0.584054   \n",
       "18       (50, 25, 12)   logistic   adam  0.436782  0.272489  0.501811   \n",
       "19       (50, 50, 25)       tanh   adam  0.268078  0.209019  0.512022   \n",
       "\n",
       "     Acc-std  \n",
       "0   0.045996  \n",
       "1   0.050926  \n",
       "2   0.026082  \n",
       "3   0.037424  \n",
       "4   0.068755  \n",
       "5   0.065719  \n",
       "6   0.073534  \n",
       "7   0.070814  \n",
       "8   0.075877  \n",
       "9   0.063751  \n",
       "10  0.063751  \n",
       "11  0.071567  \n",
       "12  0.071567  \n",
       "13  0.160849  \n",
       "14  0.143108  \n",
       "15  0.097426  \n",
       "16  0.108141  \n",
       "17  0.103411  \n",
       "18  0.007755  \n",
       "19  0.076563  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import ADASYN  # 使用 ADASYN 平衡数据\n",
    "\n",
    "# --------------------------------\n",
    "# 📦 1. 导入依赖\n",
    "# --------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# ----------------------------\n",
    "# 1. 加载数据（使用用户提供的sorted_data.csv）\n",
    "# ----------------------------\n",
    "train_data = pd.read_excel('Data_Set_(A+B).xlsx')\n",
    "\n",
    "# ----------------------------\n",
    "# 2. 特征/目标分离（保持原始逻辑）\n",
    "# ----------------------------\n",
    "# 修改点：将type=5转换为二分类目标\n",
    "X = train_data.drop(columns=[\"Type\"])  # 假设特征列不包含type列\n",
    "y = (train_data[\"Type\"] == 5).astype(int)  # 将type=5转为1，其他转为0\n",
    "\n",
    "\n",
    "# --------------------------------\n",
    "# 🔄 3. 归一化\n",
    "# --------------------------------\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# --------------------------------\n",
    "# ⚖️ 4. 使用 ADASYN 进行平衡\n",
    "# --------------------------------\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_bal, y_bal = adasyn.fit_resample(X, y)\n",
    "\n",
    "# --------------------------------\n",
    "# ⚙️ 5. 模型结构组合列表\n",
    "# --------------------------------\n",
    "config_list = config_list = [\n",
    "    # 原始配置组\n",
    "    {\"layers\": (50, 25, 12), \"activation\": \"relu\", \"solver\": \"adam\"},\n",
    "    {\"layers\": (50, 25, 12), \"activation\": \"tanh\", \"solver\": \"adam\"},\n",
    "    {\"layers\": (50, 25, 12), \"activation\": \"logistic\", \"solver\": \"adam\"},\n",
    "    {\"layers\": (50, 25, 12), \"activation\": \"relu\", \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (50, 25, 12), \"activation\": \"tanh\", \"solver\": \"lbfgs\"},\n",
    "    \n",
    "    # 扩展结构组\n",
    "    {\"layers\": (64,), \"activation\": \"relu\", \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (128, 64), \"activation\": \"relu\", \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (100, 50, 25, 10), \"activation\": \"relu\", \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (64, 32, 16, 8), \"activation\": \"relu\", \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (50, 25, 12, 6), \"activation\": \"relu\", \"solver\": \"lbfgs\"},\n",
    "    \n",
    "    # 混合配置组\n",
    "    {\"layers\": (64, 32), \"activation\": \"tanh\", \"solver\": \"adam\"},\n",
    "    {\"layers\": (64, 32), \"activation\": \"tanh\", \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (64, 32), \"activation\": \"tanh\", \"solver\": \"sgd\"},\n",
    "    \n",
    "    {\"layers\": (50, 50,25), \"activation\": \"relu\", \"solver\": \"adam\"},\n",
    "    {\"layers\": (50, 50,25), \"activation\": \"tanh\", \"solver\": \"adam\"},\n",
    "    {\"layers\": (100, 50), \"activation\": \"tanh\", \"solver\": \"adam\"},\n",
    "    {\"layers\": (128, 64, 32), \"activation\": \"relu\", \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (50, 25, 12), \"activation\": \"tanh\", \"solver\": \"lbfgs\"},\n",
    "    {\"layers\": (50, 25, 12), \"activation\": \"relu\", \"solver\": \"adam\"},\n",
    "    {\"layers\": (50, 25, 12,6), \"activation\": \"relu\", \"solver\": \"adam\"},\n",
    "]\n",
    "\n",
    "# --------------------------------\n",
    "# 🧪 6. 批量评估模型\n",
    "# --------------------------------\n",
    "results = []\n",
    "\n",
    "for cfg in config_list:\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=cfg[\"layers\"],\n",
    "        activation=cfg[\"activation\"],\n",
    "        solver=cfg[\"solver\"],\n",
    "        max_iter=500,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    scores = cross_validate(model, X_bal, y_bal, cv=4, scoring={\"f1\": \"f1\", \"accuracy\": \"accuracy\"})\n",
    "    \n",
    "    results.append({\n",
    "        \"layers\": cfg[\"layers\"],\n",
    "        \"activation\": cfg[\"activation\"],\n",
    "        \"solver\": cfg[\"solver\"],\n",
    "        \"F1-avg\": scores[\"test_f1\"].mean(),\n",
    "        \"F1-std\": scores[\"test_f1\"].std(),\n",
    "        \"Acc-avg\": scores[\"test_accuracy\"].mean(),\n",
    "        \"Acc-std\": scores[\"test_accuracy\"].std()\n",
    "    })\n",
    "\n",
    "# --------------------------------\n",
    "# 📊 7. 输出对比表格\n",
    "# --------------------------------\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results.sort_values(by=\"F1-avg\", ascending=False).reset_index(drop=True)\n",
    "df_results.head(20)  # 显示前20个最佳配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e7841bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN - F1: 0.8532, Accuracy: 0.8362\n",
      "SMOTE - F1: 0.8543, Accuracy: 0.8214\n",
      "选择 SMOTE 作为最终模型\n",
      "已保存归一化器和最佳模型：best_model_smote.pkl\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.model_selection import cross_validate\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from imblearn.over_sampling import ADASYN\n",
    "# import joblib  # 用于保存模型\n",
    "\n",
    "# # --------------------------------\n",
    "# # 📦 1. 加载排序后的训练集（sorted_data.csv）\n",
    "# # --------------------------------\n",
    "# df = pd.read_csv(\"sorted_data.csv\")  # 修改为 sorted_data.csv\n",
    "# X = df.drop(columns=[\"Type\"])  # 假设训练集包含 \"Type\" 列\n",
    "# y = (df[\"Type\"] == 5).astype(int)  # 将 Type=5 转为二分类目标（1 表示 Type=5，0 表示其他类型）\n",
    "\n",
    "# # ✅ 归一化（保持一致性）\n",
    "# scaler = MinMaxScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# # # ✅ 使用 ADASYN 平衡数据\n",
    "# # adasyn = ADASYN(random_state=42)\n",
    "# # X_bal, y_bal = adasyn.fit_resample(X_scaled, y)\n",
    "\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_bal, y_bal = smote.fit_resample(X, y)\n",
    "# # ✅ 保存 scaler（可选）\n",
    "# joblib.dump(scaler, \"minmax_scaler.pkl\")\n",
    "\n",
    "# # --------------------------------\n",
    "# # 🧠 2. 构建最佳模型\n",
    "# # --------------------------------\n",
    "# model = MLPClassifier(\n",
    "#     hidden_layer_sizes=(128, 64, 32),  # 您选定的结构\n",
    "#     activation='relu',\n",
    "#     solver='lbfgs',\n",
    "#     max_iter=500,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # 训练模型\n",
    "# model.fit(X_bal, y_bal)\n",
    "\n",
    "# # ✅ 保存模型\n",
    "# joblib.dump(model, \"best_model_adasyn.pkl\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "import joblib\n",
    "\n",
    "# 1. 读取数据\n",
    "df = pd.read_csv(\"sorted_data.csv\")\n",
    "X = df.drop(columns=[\"Type\"])\n",
    "y = (df[\"Type\"] == 5).astype(int)\n",
    "\n",
    "# 2. 归一化\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 3. 定义模型\n",
    "def create_model():\n",
    "    return MLPClassifier(\n",
    "        hidden_layer_sizes=(128, 64),\n",
    "        activation='relu',\n",
    "        solver='lbfgs',\n",
    "        max_iter=500,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "# 4. 定义评估函数\n",
    "def evaluate_oversampler(oversampler, X, y):\n",
    "    X_bal, y_bal = oversampler.fit_resample(X, y)\n",
    "    model = create_model()\n",
    "    scoring = ['f1', 'accuracy']\n",
    "    scores = cross_validate(model, X_bal, y_bal, cv=4, scoring=scoring)\n",
    "    f1_mean = scores['test_f1'].mean()\n",
    "    acc_mean = scores['test_accuracy'].mean()\n",
    "    return f1_mean, acc_mean, model, X_bal, y_bal\n",
    "\n",
    "# 5. 评估 ADASYN\n",
    "adasyn = ADASYN(random_state=42)\n",
    "f1_ada, acc_ada, model_ada, X_ada, y_ada = evaluate_oversampler(adasyn, X_scaled, y)\n",
    "print(f\"ADASYN - F1: {f1_ada:.4f}, Accuracy: {acc_ada:.4f}\")\n",
    "\n",
    "# 6. 评估 SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "f1_smote, acc_smote, model_smote, X_smote, y_smote = evaluate_oversampler(smote, X_scaled, y)\n",
    "print(f\"SMOTE - F1: {f1_smote:.4f}, Accuracy: {acc_smote:.4f}\")\n",
    "\n",
    "# 7. 选择最佳模型\n",
    "if f1_ada > f1_smote:\n",
    "    print(\"选择 ADASYN 作为最终模型\")\n",
    "    best_model = model_ada\n",
    "    best_X, best_y = X_ada, y_ada\n",
    "    best_name = \"adasyn\"\n",
    "else:\n",
    "    print(\"选择 SMOTE 作为最终模型\")\n",
    "    best_model = model_smote\n",
    "    best_X, best_y = X_smote, y_smote\n",
    "    best_name = \"smote\"\n",
    "\n",
    "# 8. 用全部平衡数据训练最佳模型\n",
    "best_model.fit(best_X, best_y)\n",
    "\n",
    "# 9. 保存归一化器和模型\n",
    "joblib.dump(scaler, \"minmax_scaler.pkl\")\n",
    "joblib.dump(best_model, f\"best_model_{best_name}.pkl\")\n",
    "print(f\"已保存归一化器和最佳模型：best_model_{best_name}.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
